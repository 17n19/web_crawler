# web_crawler
 This crawler have robotness and politeness.
 
 This crawler will crawl to websites and download their `.html` sites and store them in `html folder`. 
 
 And if website have `robots.txt` or `sitemap.xml`, the website's `hostname` will be stored in `list_robots.txt` or/and `list_sitemap.txt`.
 
